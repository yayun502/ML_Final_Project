{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datasets: target(y_train) / train(X_train) / data(X_train + X_test) \n",
    "target = train['failure']\n",
    "train = train.drop('failure', axis=1)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding missing values as extra columns => observe failure rate when feature is missing \n",
    "data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
    "data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in test.columns if col.startswith('measurement')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float type columns => find 4 most correlated columns for measurement_3 ~ measurement_17\n",
    "col_corrsum = list()\n",
    "col_name = list()\n",
    "for x in range(3, 18):   \n",
    "    corr = np.absolute(data[cols].corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
    "    col_corrsum.append(np.round(np.sum(corr[1:5]),5))\n",
    "    col_name.append(f'measurement_{x}')\n",
    "\n",
    "# 計算哪些欄位 和其他欄位有較大關聯性\n",
    "# create df for it\n",
    "c = pd.DataFrame()\n",
    "c['Selected columns'] = col_name\n",
    "c['correlation total'] = col_corrsum\n",
    "c = c.sort_values(by = 'correlation total', ascending=False).reset_index(drop = True)\n",
    "\n",
    "# 和其他欄位有較大關聯性的這些欄位 在各product code中關聯性表現如何 \n",
    "# create dictionary for it => convenient for looking up\n",
    "dict = {}\n",
    "for i in range(8):\n",
    "    selected_col = c.loc[i, 'Selected columns']\n",
    "    selected_col_dic = {}\n",
    "    for pc in data.product_code.unique(): \n",
    "        corr = np.absolute(data.loc[data.product_code == pc, cols].corr()[selected_col]).sort_values(ascending=False)\n",
    "        # print(f'product code: {x}, selected columns: {selected_col}, corr: ')\n",
    "        # print(corr)\n",
    "        selected_col_dic[pc] = list(corr[1:5].index)\n",
    "    dict[selected_col] = selected_col_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col.startswith('measurement') or col=='loading']\n",
    "null_cols = [col for col in train.columns if train[col].isnull().sum()!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#filled (by linear model) = 1499\n",
      "#filled (by KNN) = 3829\n"
     ]
    }
   ],
   "source": [
    "# fill NaN/null value \n",
    "for pc in data.product_code.unique():\n",
    "    \n",
    "    num_NaN_filled_byModel = 0\n",
    "    num_NaN_filled_byKNN = 0\n",
    "\n",
    "    # print(f'Product code {pc}: filled by linear model (HuberRegressor):')\n",
    "    for selected_col in dict.keys():\n",
    "        # try to fill NaN (if meeting requirements about features needed) => use those to train a model \n",
    "        data_with_specific_pc = data[data.product_code == pc]\n",
    "        features_train = [selected_col] + dict[selected_col][pc]   # dict[selected_col][pc]=look up dictionary(for selected_col performing in the specific product code)\n",
    "        L_train = data_with_specific_pc[features_train].dropna(axis=0, how='any')  # use features_train to train linear model(also drop NaN row)\n",
    "        LX_train = L_train[dict[selected_col][pc]]\n",
    "        Ly_train = L_train[selected_col]\n",
    "        subdata_pc = data[data.product_code == pc][features_train]\n",
    "        condition1 = (subdata_pc[dict[selected_col][pc]].isnull().sum(axis=1) == 0)  # axis=1 : cross columns\n",
    "        condition2 = (subdata_pc[selected_col].isnull())\n",
    "        LX_test = subdata_pc[condition1 & condition2]\n",
    "        # print(len(LX_train), len(LX_test))\n",
    "\n",
    "        if(len(LX_train)!=0 and len(LX_test)!=0):\n",
    "            model = HuberRegressor(epsilon=1.35, max_iter=400)\n",
    "            model.fit(LX_train, Ly_train)\n",
    "            prediction = model.predict(data[data.product_code == pc].loc[LX_test.index.tolist(), dict[selected_col][pc]])\n",
    "            data[data.product_code == pc].loc[LX_test.index.tolist(), selected_col]= prediction\n",
    "            # print(f\"fill '{selected_col}': #row = {len(LX_test)}\")\n",
    "            num_NaN_filled_byModel += len(LX_test)\n",
    "        \n",
    "    # columns still NaN/null (result from not meeting requirements about features needed) => use 'features' to impute\n",
    "    num_NaN_filled_byKNN = data.loc[data[\"product_code\"] == pc, null_cols].isnull().sum().sum()\n",
    "    knn = KNNImputer(n_neighbors=3)\n",
    "    data.loc[data.product_code==pc, features] = knn.fit_transform(data.loc[data.product_code==pc, features])\n",
    "\n",
    "print(f'#filled (by linear model) = {num_NaN_filled_byModel}') \n",
    "print(f'#filled (by KNN) = {num_NaN_filled_byKNN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling for the certain features columns \n",
    "def scaling_specific_features(df_list, features):\n",
    "    \n",
    "    df_new_list = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        # fit and transform\n",
    "        if i==0:\n",
    "            df_scaled = scaler.fit_transform(df[features])\n",
    "        else:\n",
    "            df_scaled = scaler.transform(df[features])\n",
    "        # put it back\n",
    "        df_new = df.copy()\n",
    "        df_new[features] = df_scaled\n",
    "        df_new_list.append(df_new)\n",
    "    \n",
    "    return df_new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # labeling for 'attribute_1' => use LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# data['attribute_1'] = le.fit_transform(data['attribute_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clip for 'measurement_2' => y correlated when this values > 10\n",
    "# data['measurement_2'] = data['measurement_2'].clip(lower=11, upper=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload train/test because preprocessing\n",
    "train = data.iloc[:len(train),:]\n",
    "test = data.iloc[len(train):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "y = target\n",
    "# labeling for 'attribute_0' => use WoEEncoder\n",
    "woe_encoder = WoEEncoder(variables=['attribute_0'])\n",
    "woe_encoder.fit(X, y)\n",
    "X = woe_encoder.transform(X)\n",
    "test = woe_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick based on correlation analysis and important_list \n",
    "features_for_training = ['loading',\n",
    "                        'attribute_0',\n",
    "                        'measurement_17',\n",
    "                        'measurement_0',\n",
    "                        'measurement_1',\n",
    "                        'measurement_2',\n",
    "                        'm3_missing',\n",
    "                        'm5_missing',\n",
    "                        # 'attribute_3',\n",
    "                        # 'measurement_4',\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy : StratifiedGroupKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "Fold: 1 => ROC-AUC: 0.58145\n",
      "Fold: 2 => ROC-AUC: 0.59798\n",
      "Fold: 3 => ROC-AUC: 0.59146\n",
      "Fold: 4 => ROC-AUC: 0.59397\n",
      "Fold: 5 => ROC-AUC: 0.58682\n",
      "Average ROC-AUC = 0.5903374932212958\n",
      "Strategy : StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "Fold: 1 => ROC-AUC: 0.60195\n",
      "Fold: 2 => ROC-AUC: 0.59369\n",
      "Fold: 3 => ROC-AUC: 0.58225\n",
      "Fold: 4 => ROC-AUC: 0.59426\n",
      "Fold: 5 => ROC-AUC: 0.58649\n",
      "Average ROC-AUC = 0.591726973363407\n",
      "Strategy : GroupKFold(n_splits=5)\n",
      "Fold: 1 => ROC-AUC: 0.58682\n",
      "Fold: 2 => ROC-AUC: 0.58145\n",
      "Fold: 3 => ROC-AUC: 0.59146\n",
      "Fold: 4 => ROC-AUC: 0.59798\n",
      "Fold: 5 => ROC-AUC: 0.59397\n",
      "Average ROC-AUC = 0.5903374932212958\n"
     ]
    }
   ],
   "source": [
    "# try different strategies of cross validation\n",
    "for kf in [StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=0), StratifiedKFold(n_splits=5, shuffle=True, random_state=0), GroupKFold(n_splits=5)]:\n",
    "    print(f'Strategy : {kf}')\n",
    "    prediction = np.zeros(len(test))\n",
    "    roc_auc = 0\n",
    "    importance_list = []\n",
    "\n",
    "    # fold loop\n",
    "    for num_fold, (train_index, val_index) in enumerate(kf.split(X, y, X.product_code)):\n",
    "        # set dataset \n",
    "        x_train = X.iloc[train_index]\n",
    "        x_valid = X.iloc[val_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_valid = y.iloc[val_index]\n",
    "        \n",
    "        # scaling\n",
    "        df_list = [x_train, x_valid, test]\n",
    "        x_train, x_valid, x_test = scaling_specific_features(df_list, features_for_training)\n",
    "\n",
    "        # training\n",
    "        model = linear_model.LogisticRegression(max_iter=100, C=0.0001, penalty='l2', solver='liblinear')\n",
    "        model.fit(x_train[features_for_training], y_train)\n",
    "        importance_list.append(model.coef_.ravel())\n",
    "\n",
    "        # validation\n",
    "        y_pred_valid = model.predict_proba(x_valid[features_for_training])[:, 1]\n",
    "        print(f\"Fold: {num_fold+1} => ROC-AUC: {round(roc_auc_score(y_valid, y_pred_valid), 5)}\")\n",
    "        roc_auc += roc_auc_score(y_valid, y_pred_valid) / 5\n",
    "        prediction += model.predict_proba(x_test[features_for_training])[:, 1] / 5\n",
    "\n",
    "    print(f\"Average ROC-AUC = {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39069472, 0.38167169, 0.38640681, ..., 0.37460454, 0.40397887,\n",
       "       0.38163977])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv file\n",
    "with open('submission_best_privateScore.csv', 'w', newline='') as csvfile:\n",
    "  csv_writer = csv.writer(csvfile)\n",
    "  csv_writer.writerow([\"id\", \"failure\"])\n",
    "  for id, value in zip(list(test.id), prediction):\n",
    "    csv_writer.writerow([id, value])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use full train dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20192883, 0.19422158, 0.19818543, ..., 0.18903897, 0.21466629,\n",
       "       0.19475708])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model = linear_model.LogisticRegression(max_iter=100, C=0.0001, penalty='l2', solver='newton-cg')\n",
    "x_train, x_test = scaling_specific_features([X, test], features_for_training)\n",
    "model.fit(x_train[features_for_training], y)\n",
    "prediction_full = model.predict_proba(x_test[features_for_training])[:, 1]\n",
    "\n",
    "# y_pred\n",
    "prediction_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model \n",
    "pickle.dump(model, open('model_best_publicScore.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv file\n",
    "with open('submission_best_publicScore.csv', 'w', newline='') as csvfile:\n",
    "  csv_writer = csv.writer(csvfile)\n",
    "  csv_writer.writerow([\"id\", \"failure\"])\n",
    "  for id, value in zip(list(test.id), prediction_full):\n",
    "    csv_writer.writerow([id, value])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find better parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_df__X\n",
    "# y = train_df__y\n",
    "# test = test_df\n",
    "# for kf in [StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=0), StratifiedKFold(n_splits=5, shuffle=True, random_state=0), GroupKFold(n_splits=5)]:\n",
    "#     print(f'Strategy : {kf}')\n",
    "#     prediction = np.zeros(len(test))\n",
    "#     best_roc_auc = 0\n",
    "#     best_accuracy = 0\n",
    "#     best_roc_auc_model = None\n",
    "#     best_accuracy_model = None\n",
    "#     importance_list = []\n",
    "\n",
    "#     penalties = ['none', 'l2', 'l1', 'elasticnet']\n",
    "#     Cs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "#     solvers = ['lbfgs', 'newton-cg', 'newton-cholesky', 'liblinear', 'sag', 'saga']\n",
    "#     l1_ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#     for solver in solvers[:3]:\n",
    "#         for penalty in penalties[:2]:\n",
    "#             for C in Cs:\n",
    "#                 roc_auc = 0\n",
    "#                 accuracy = 0\n",
    "#                 for num_fold, (train_index, val_index) in enumerate(kf.split(X, y, X.product_code)):\n",
    "#                     x_train = X.iloc[train_index]\n",
    "#                     x_valid = X.iloc[val_index]\n",
    "#                     y_train = y.iloc[train_index]\n",
    "#                     y_valid = y.iloc[val_index]\n",
    "#                     x_train, x_valid, x_test = scaling_specific_features(x_train, x_valid, test, features_for_training)\n",
    "\n",
    "#                     model = linear_model.LogisticRegression(max_iter=100, C=C, penalty=penalty, solver=solver)\n",
    "#                     # model = linear_model.LogisticRegression(max_iter=100, C=C, penalty=penalty, solver=solver, random_state=0)\n",
    "#                     # model = linear_model.LogisticRegression(max_iter=100, C=C, penalty=penalty, solver=solver, random_state=0, l1_ratio=l1_ratio)\n",
    "#                     model.fit(x_train[features_for_training], y_train)\n",
    "#                     importance_list.append(model.coef_.ravel())\n",
    "\n",
    "#                     y_pred_valid = model.predict_proba(x_valid[features_for_training])[:, 1]\n",
    "#                     y_pred_valid2 = model.predict(x_valid[features_for_training])\n",
    "\n",
    "#                     # print(f\"Fold: {num_fold+1} => ROC-AUC: {round(roc_auc_score(y_valid, y_pred_valid), 5)}  accuracy: {round(accuracy_score(y_valid, y_pred_valid2),5)}\")\n",
    "#                     roc_auc += roc_auc_score(y_valid, y_pred_valid) / 5\n",
    "#                     accuracy += accuracy_score(y_valid, y_pred_valid2) / 5\n",
    "#                     prediction += model.predict_proba(x_test[features_for_training])[:, 1] / 5\n",
    "\n",
    "#                 print(f\"kf={kf} C={C} penalty={penalty} solver={solver} l1_ratio={l1_ratio}\")\n",
    "#                 print(f\"Average ROC-AUC = {roc_auc}  Average accuracy = {accuracy}\")\n",
    "#                 if roc_auc>best_roc_auc:\n",
    "#                     best_roc_auc = roc_auc\n",
    "#                     best_roc_auc_model = f\"kf={kf} C={C} penalty={penalty} solver={solver} l1_ratio={l1_ratio}\"\n",
    "#                 if accuracy>best_accuracy:\n",
    "#                     best_accuracy = accuracy\n",
    "#                     best_accuracy_model = f\"kf={kf} C={C} penalty={penalty} solver={solver} l1_ratio={l1_ratio}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_roc_auc, best_roc_auc_model)\n",
    "# print(best_accuracy, best_accuracy_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Ensemble (w/Soft voting) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, GroupKFold\n",
    "# from sklearn.svm import SVC, SVR\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation\n",
    "# import warnings\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# train_df = pd.read_csv('train.csv', index_col='id')\n",
    "# test_df = pd.read_csv('test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df.failure\n",
    "\n",
    "# def get_models():\n",
    "#     models = []\n",
    "#     models.append(('lr_1', LogisticRegression(penalty='l1', C=0.01, solver='liblinear', random_state=1)))\n",
    "#     models.append(('lr_2', LogisticRegression(max_iter=500, C=0.0001, penalty='l2', solver='newton-cg', random_state=1)))\n",
    "#     models.append(('bayes', GaussianNB(var_smoothing=0.5, priors=[len(y[y == 0]) / len(y), len(y[y == 1])/len(y)])))\n",
    "#     models.append(('adaboost', AdaBoostClassifier(n_estimators=100, random_state=12)))\n",
    "#     models.append(('mlp', MLPClassifier(alpha=0.1, max_iter=1000)))\n",
    "#     return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracys = []\n",
    "# y_pred = []\n",
    "# importance_features = []\n",
    "# # GroupKFold：保證同一個group的數據不會同時出現在訓練集和測試集上\n",
    "# gkf = GroupKFold(n_splits=5) # 5 product codes => n_splits=5\n",
    "# all_features = test_df.columns\n",
    "\n",
    "# for num_fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.failure, groups=train_df.product_code)):\n",
    "#     X_train = train_df.iloc[train_index][all_features]\n",
    "#     y_train = train_df.iloc[train_index].failure\n",
    "#     X_valid = train_df.iloc[valid_index][all_features]\n",
    "#     y_valid = train_df.iloc[valid_index].failure\n",
    "#     X_test = test_df.copy()\n",
    "\n",
    "#     # one-hot encoding for attribute_0, attribute_1\n",
    "#     # drop first：ensure there are no \"reference\" columns (= the remaining columns become linearly independent.)\n",
    "#     encoding_attributes = ['attribute_0', 'attribute_1']\n",
    "#     encoding_output = ['encoding_7', 'encoding_6', 'encoding_8']\n",
    "#     encoder = OneHotEncoder(categories=[['material_5', 'material_7'],['material_5', 'material_6', 'material_8']],\n",
    "#                         drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "#     encoder.fit(X_train[encoding_attributes])\n",
    "\n",
    "#     for df in [X_train, X_valid, X_test]:\n",
    "#         with warnings.catch_warnings():  # ignore \"Found unknown categories\"\n",
    "#             warnings.filterwarnings('ignore', category=UserWarning)\n",
    "#             df[encoding_output] = encoder.transform(df[encoding_attributes])  # add new features after encoding\n",
    "#         df.drop(columns=encoding_attributes, inplace=True)  # delete old features before encoding\n",
    "\n",
    "#     # add new features for missing values\n",
    "#     for df in [X_train, X_valid, X_test]:\n",
    "#         df['m_3_missing'] = df.measurement_3.isna()\n",
    "#         df['m_5_missing'] = df.measurement_5.isna()\n",
    "    \n",
    "#     # Impute the missing values based on product code \n",
    "#     features_may_have_nan = [c for c in X_train.columns if c == 'loading' or c.startswith('measurement')]\n",
    "#     imputer = KNNImputer(n_neighbors=3)\n",
    "#     for df in [X_train, X_valid, X_test]:\n",
    "#         for pc in list((df.groupby('product_code')['product_code']).count().index):\n",
    "#             df.loc[df['product_code']==pc, features_may_have_nan] = imputer.fit_transform(df.loc[df['product_code']==pc, features_may_have_nan])\n",
    "\n",
    "#     # Clip measurement_2 => y correlated when this values > 10 \n",
    "#     for df in [X_train, X_valid, X_test]:\n",
    "#         df['measurement_2'] = df['measurement_2'].clip(lower=11, upper=None)\n",
    "    \n",
    "#     # Standardize data (StandardScaler) + train model\n",
    "#     features_for_training = ['loading', 'attribute_3', 'measurement_2', 'measurement_4', 'measurement_17', 'm_3_missing', 'm_5_missing']\n",
    "#     # features_for_training = [f for f in X_train.columns if f != 'product_code']  # remove product_code\n",
    "#     scores = []\n",
    "#     for (name, md) in get_models():\n",
    "#         model = make_pipeline(StandardScaler(), \n",
    "#                             md)\n",
    "                          \n",
    "#         model.fit(X_train[features_for_training], y_train)\n",
    "#         # importance_features.append(model.named_steps['logisticregression'].coef_.ravel())\n",
    "\n",
    "#         # validation\n",
    "#         y_pred_valid = model.predict(X_valid[features_for_training])\n",
    "#         score = accuracy_score(y_valid, y_pred_valid)\n",
    "#         print(f\"Model {name}  Fold {num_fold}: accuracy = {score:.5f}\")\n",
    "#         scores.append(score)\n",
    "#     accuracys.append(scores)\n",
    "#     y_pred.append(model.predict(X_test[features_for_training]))\n",
    "\n",
    "# # print overall score\n",
    "# # print(f\"Average accuracy = {sum(accuracys) / len(accuracys):.5f}\")\n",
    "# print('============================================')\n",
    "# model_scores = []\n",
    "# for i in range(len(accuracys[0])):\n",
    "#     sum = 0\n",
    "#     for j in range(len(accuracys)):\n",
    "#         sum += accuracys[j][i]\n",
    "#     print(f\"Average accuracy = {sum / len(accuracys):.5f}\")\n",
    "#     model_scores.append(sum / len(accuracys))\n",
    "# print('============================================')\n",
    "# print(y_pred)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6a0ffad3a294a4eb8b29a8c17e7671d526bb3fd9e88c0a2803a38bee8b75c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
